{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "dataset_path = r\"F:/Cancer Pred/Blood cell Cancer [ALL]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for each class label\n",
    "class_paths = {\n",
    "    \"Early Pre-B\": r\"F:\\Cancer Pred\\Blood cell Cancer [ALL]\\[Malignant] Early Pre-B\",\n",
    "    \"Pre-B\": r\"F:\\Cancer Pred\\Blood cell Cancer [ALL]\\[Malignant] Pre-B\",\n",
    "    \"Pro-B\": r\"F:\\Cancer Pred\\Blood cell Cancer [ALL]\\[Malignant] Pro-B\",\n",
    "    \"Benign\": r\"F:\\Cancer Pred\\Blood cell Cancer [ALL]\\Benign\"\n",
    "}\n",
    "\n",
    "# Check if directories exist\n",
    "for class_label, class_path in class_paths.items():\n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"Directory not found: {class_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store images and labels\n",
    "X = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_images_from_directory(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_name in os.listdir(directory):\n",
    "        image_path = os.path.join(directory, image_name)\n",
    "        try:\n",
    "            # Load and preprocess the image\n",
    "            image = load_img(image_path, target_size=target_size)\n",
    "            image = img_to_array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(image)\n",
    "            labels.append(class_label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store images and labels\n",
    "all_images = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels from each class directory\n",
    "for class_label, class_path in class_paths.items():\n",
    "    if os.path.exists(class_path):\n",
    "        images, labels = load_images_from_directory(class_path)\n",
    "        all_images.extend(images)\n",
    "        all_labels.extend(labels)\n",
    "    else:\n",
    "        print(f\"Directory not found: {class_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "indices = np.arange(all_images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "all_images = all_images[indices]\n",
    "all_labels = all_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images array: (3242, 128, 128, 3)\n",
      "Shape of labels array: (3242,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the loaded data\n",
    "print(\"Shape of images array:\", all_images.shape)\n",
    "print(\"Shape of labels array:\", all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=80)\n",
    "\n",
    "# Resize the input images to match the model's input shape\n",
    "X_train_resized = np.array([cv2.resize(image, (224, 224)) for image in X_train])\n",
    "X_test_resized = np.array([cv2.resize(image, (224, 224)) for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert string labels to numerical categories\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(class_labels), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 46s 524ms/step - loss: 0.9155 - accuracy: 0.6437 - val_loss: 0.5210 - val_accuracy: 0.7951\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 36s 442ms/step - loss: 0.3863 - accuracy: 0.8457 - val_loss: 0.3805 - val_accuracy: 0.8351\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 36s 443ms/step - loss: 0.3745 - accuracy: 0.8585 - val_loss: 0.7211 - val_accuracy: 0.6949\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 36s 442ms/step - loss: 0.2698 - accuracy: 0.8970 - val_loss: 0.4744 - val_accuracy: 0.8259\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 36s 440ms/step - loss: 0.2126 - accuracy: 0.9179 - val_loss: 0.3501 - val_accuracy: 0.8567\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 36s 441ms/step - loss: 0.1836 - accuracy: 0.9337 - val_loss: 0.3391 - val_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 36s 440ms/step - loss: 0.1252 - accuracy: 0.9603 - val_loss: 0.3625 - val_accuracy: 0.8875\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 36s 438ms/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.4896 - val_accuracy: 0.8829\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 36s 438ms/step - loss: 0.0728 - accuracy: 0.9776 - val_loss: 0.5083 - val_accuracy: 0.8875\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 36s 440ms/step - loss: 0.1142 - accuracy: 0.9595 - val_loss: 0.5653 - val_accuracy: 0.8706\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.5653 - accuracy: 0.8706\n",
      "Test Accuracy: 0.8705701231956482\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_resized, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test_resized, y_test_encoded))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_resized, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 3s 131ms/step - loss: 0.5653 - accuracy: 0.8706\n",
      "Test Accuracy: 0.8705701231956482\n"
     ]
    }
   ],
   "source": [
    "# Resize test images to match the input shape of the model\n",
    "X_test_resized = np.array([cv2.resize(img, (224, 224)) for img in X_test])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_resized, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"blood_cell1_cancer_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
